{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectifs\n",
    "\n",
    "- **manipulation de textes** en vue de leur préparation pour une tâche d'apprentissage automatique : manipuler du texte \"authentique\" français produit par des internautes, pour en produire des représentations qui mettent en oeuvre une réduction des variables textuelles à différents degrés d'agressivité ;\n",
    "\n",
    "- **apprentissage automatique** : entraîner et évaluer des modèles de classification automatique des textes préparés ;\n",
    "\n",
    "- **maîtrise d'outils** : utilisation de librairies qui implémentent des fonctionnalités de manipulation de texte (`spacy`, `nltk`), de données tabulaires (`pandas`) ou d'apprentissage automatique (`scikit-learn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description de la tâche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tâche :__ classification (catégorisation) multi-classe (trois classes)\n",
    "\n",
    "__Type de données :__ texte, tweets\n",
    "\n",
    "__Langue :__ français\n",
    "\n",
    "__Output :__ polarité du texte: positif, négatif, neutre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Installation et) importation des outils nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk : en général limité quant au traitement du français\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer # ou: from nltk.stem.snowball import FrenchStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# En ligne de commande\n",
    "# !pip install -U spacy\n",
    "## !python -m spacy download fr\n",
    "# !python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy : bonne couverture du français ; très efficace\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION : Les données de test sont destinées à une évaluation FINALE du modèle entraîné. Elles ne doivent sous aucune forme servir à la conception du modèle. Il est donc interdit de les examiner. La sélection itérative du meilleur modèle se fera en évaluant les différentes variantes du modèle (en faisant varier des hyper-paramètres) sur un jeu de données de validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) Récupération et mise en forme des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données du défi [DEFT2015](https://deft.limsi.fr/2015/corpus.fr.php?lang=fr) : tweets rédigés en français, portant sur la thématique des changements climatiques. Tweets annotés selon leur polarité, pour la tâche 1 du défi : \"Classification des tweets selon leur polarité. Étant donné un tweet, cette tâche consiste à le classer, selon l’opinion/sentiment/émotion qu'il exprime, en positif, négatif, neutre ou mixte (si le tweet contient à la fois un sentiment positif et un sentiment négatif).\"\n",
    "\n",
    "__ATTENTION : Ces jeux de données ont été mis à notre disposition EXCLUSIVEMENT à des fins pédagogiques par les organisateurs du défi DEFT 2015. Leur redistribution est formellement interdite et tout travail écrit (rapport de stage, article, etc.) produit sur la base de ces données devra citer les sources indiquées sur le [site Web de DEFT 2015](https://deft.limsi.fr/2015/corpus.fr.php?lang=fr).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les étiquettes (la vérité terrain) et le texte des tweets sont stockés séparément. Nous les regrouperons à partir de l'identifiant du tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_label_file_path(parent_label_directory, train_or_test):\n",
    "    return os.path.join(parent_label_directory,\n",
    "                        '{}_References'.format(train_or_test.title()),\n",
    "                        'T1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_label_to_numeric(label):\n",
    "    return 1 if label == '+' else 0 if label == '=' else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(parent_label_directory, train_or_test):\n",
    "    label_file = make_label_file_path(parent_label_directory, train_or_test)\n",
    "    labels = pd.read_table(label_file, header=None, names=['id', 'polarity'])\n",
    "    labels['polarity'] = labels['polarity'].apply(map_label_to_numeric)\n",
    "    labels.set_index('id', inplace=True)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = get_labels('data', 'train')\n",
    "test_labels = get_labels('data', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    polarity\n",
       "id                          \n",
       "487349133460918272         1\n",
       "487354248959918080        -1\n",
       "487360225654374401         0\n",
       "487387097222098944        -1\n",
       "487387321537269761         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7929, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data_dir_path(parent_data_directory, train_or_test):\n",
    "    return os.path.join(parent_data_directory,\n",
    "                        'deft2015_{}_twitter_raw'.format(train_or_test.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweets(parent_data_directory, train_or_test):\n",
    "    if train_or_test == 'test':\n",
    "        train_or_test += 's' # incohérence dans le nommage des répertoires\n",
    "    data_dir = make_data_dir_path(parent_data_dir, train_or_test)\n",
    "    tweets = dict()\n",
    "\n",
    "    for file_name in sorted(os.listdir(data_dir)):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            with open(os.path.join(data_dir, file_name), 'r') as f:\n",
    "                text = f.read()\n",
    "            id_tweet = int(os.path.splitext(file_name)[0])\n",
    "            tweets[id_tweet] = text\n",
    "    \n",
    "    return (pd.DataFrame.from_dict(tweets, orient='index')\n",
    "                        .rename(columns={0: 'text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_data_dir = 'data/twitter'\n",
    "train_tweets = get_tweets(parent_data_dir, 'train')\n",
    "test_tweets = get_tweets(parent_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...\n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...\n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n\n",
       "487387097222098944                  Développement durable ma gueule\\n\n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*QUESTION : Combien de tweets y a-t-il dans le jeu de données d'entraînement et dans celui de test ?*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7511, 3285)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tweets), len(test_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Jonction des textes et des étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plus d'étiquettes que de textes, car des tweets ont pu disparaître entre le moment où ils ont été collectés pour l'annotation de référence et le moment où ils ont été récupérés ultérieurement (voir [ici](https://deft.limsi.fr/2015/evaluation.fr.php?lang=fr)). Nous ferons une jointure interne pour ne retenir que les éléments communs aux deux tableaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, tous les tweets disponibles ont une étiquette :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_tweets.index).intersection(set(train_labels.index))) == len(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_tweets_and_labels(tweets_df, labels_df):\n",
    "    return pd.merge(tweets_df, labels_df, how='inner',\n",
    "                    left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets = merge_tweets_and_labels(train_tweets, train_labels)\n",
    "test_tweets = merge_tweets_and_labels(test_tweets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...   \n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...   \n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n   \n",
       "487387097222098944                  Développement durable ma gueule\\n   \n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ...   \n",
       "\n",
       "                    polarity  \n",
       "487349133460918272         1  \n",
       "487354248959918080        -1  \n",
       "487360225654374401         0  \n",
       "487387097222098944        -1  \n",
       "487387321537269761         0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_distribution = (pd.DataFrame.from_dict(Counter(train_tweets.polarity.values),\n",
    "                                             orient='index')\n",
    "                                  .rename(columns={0: 'num_examples'}))\n",
    "class_distribution.index.name = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples\n",
       "class              \n",
       " 1             2364\n",
       "-1             1763\n",
       " 0             3384"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_distribution['perc_examples'] = np.around(class_distribution.num_examples /\n",
    "                                                np.sum(class_distribution.num_examples), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "      <th>perc_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2364</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1763</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3384</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples  perc_examples\n",
       "class                             \n",
       " 1             2364           0.31\n",
       "-1             1763           0.23\n",
       " 0             3384           0.45"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Exploration du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION :** Ne pas regarder les données de test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"#Question orale à @RoyalSegolene au sujet de l'efficacité énergétique de @MicheleBonneton http://t.co/RrHxGn5URS @Dailymotion\\n\",\n",
       "       \"@PhanEd @AznAlainT @_Baekholic alors j'ai une blague mais dure a comprendre: On est ecologiques a nous 3 on se rebelle groupe Anti-Train !\\n\",\n",
       "       '\"On peut vendre du vent, regarde les éoliennes\"\\n',\n",
       "       'Développement durable ma gueule\\n',\n",
       "       \"Quand l'cosystme numrique bordelais rencontre la mission French Tech nationale http://t.co/oCqL9tb4SZ\\n\",\n",
       "       'Madame Ségolène Royale, ministre de l\\'écologie et du développement durable : Non, à la destruction des \"nuisibles\" http://t.co/jUYWddlIMe\\n',\n",
       "       'Le nouveau Monsieur \" développement durable \": Jacques Tapin, l’ex-élu municipal niortais, vient d’être porté ... http://t.co/hrDGKOkyJd\\n',\n",
       "       'Le ciment s’offre une empreinte carbone réduite: Si le ciment est connu pour ses qualités écologiques, il est ... http://t.co/Gd028bTRe2\\n',\n",
       "       \"J'ai mis à jour mon profil Viadeo : http://t.co/pdQtQFh9Sz\\n\",\n",
       "       '@F_Choquette  pourquoi une pétition contre le changement climatique si vous etes meme pas capable de traiter un simple dossier citoyen\\n',\n",
       "       '\"Quand l\\'écosystème numérique bordelais rencontre la mission French Tech nationale …\"  http://t.co/QtgZ1zLIcT good read\\n',\n",
       "       \"Ad exchange et DMP: l'écosystème digital en route pour inventer les subprimes de la #pub en faisant croire bundle YouTube+socialTV+data=TF1?\\n\",\n",
       "       \"Content de participer au groupe de travail @LaFabriqueEcolo sur mondialisation et développement durable, beaucoup d'échanges et d'énergie\\n\",\n",
       "       \"Camping rime aujourd'hui avec technologie : la preuve en est avec cette tente aux capteurs solaires intégrés dans... http://t.co/ylRP0Ua5Wd\\n\",\n",
       "       '7 Principes de l’Engagement #RSE du #Dirigeant | @CalvoConstant http://t.co/QSorpZGxgE\\n'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets['text'].values[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER', 'PER', 'PER']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nlp('Le nouveau Monsieur \" développement durable \": Jacques Tapin, l’ex-élu municipal niortais, vient d’être porté ... http://t.co/hrDGKOkyJd\\n')\n",
    "[ent.label_ for ent in s.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentation des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Du texte au numérique:**\n",
    "\n",
    "- les descripteurs (variables, features, traits) sont des unités textuelles (lemmes, racines, autres ; prises individuellement ou en séquences, etc.) (mais on peut leur ajouter des variables non-textuelles) ;\n",
    "\n",
    "- les valeurs de ces variables sont numériques : binaires, numériques discrètes, numérique continues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texte vs corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Traditionnellement : les descripteurs textuels sont calculés sur l'ensemble du corpus. Tous les textes sont représentés par le mêmes ensemble de descripteurs, ce qui fait que la représentation d'un texte est un grand vecteur épars de taille fixe (taille du vecteur = taille du vocabulaire du corpus).\n",
    "\n",
    "Approches plus récentes : chaque mot est représenté par un vecteur dense de valeurs réelles. Le texte est représenté par une aggrégation sous une certaine forme des représentations de ses mots constituants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sélection de descripteurs : prétraitements textuels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : réduire le nombre de descripteurs : réduire à un seul descripteur ceux qui sont équivalents ou qui peuvent être regroupés dans une classe d'équivalence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisation, racinisation, normalisation/correction ortho, suppression des accents, minuscules?, suppression de la ponctuation (penser si on veut en garder certains ; **traiter la négation à part !**), mots vides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire une regex, e.g. pour remplacer les adresses mail, les hashtags, les nombres, etc. par des placeholders. Classes de caractères Unicode (comprend des caractères non-ASCII) : `\\w`, `\\d`. OU BIEN : faire une REN avec `spacy` et remplacer les entités par leur classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#Question orale à @RoyalSegolene au sujet de l'efficacité énergétique de @MicheleBonneton http://t.co/RrHxGn5URS @Dailymotion"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple\n",
    "tw = nlp(train_tweets['text'].iloc[0])\n",
    "tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.** Dans la pratique certains ces procédés sont souvent appliqués ensemble ou bien ils peuvent être pris en charge par l'implémentation de la méthode d'apprentissage même, qui les applique en boîte noire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Pas de sélection : mots tels quels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in tw:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Réduction par regroupement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer chaque fois l'importance de la réduction (entre la taille du vocabulaire réduit / taille du vocabulaire initial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Lemmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in tw:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Racines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw = tweets['text'].iloc[0]\n",
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "tokenizer.tokenize(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in tokenizer.tokenize(tw):\n",
    "    print(stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3. Étiquettes morphosyntaxiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in nlp(tw):\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4. Classe d'appartenance des entités nommées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limites : reconnaissance imparfaite. Faire des essais pour appréhender les limites de l'outil (erreurs systématiques, etc.). Dans notre cas, il vaut mieux éliminer les URL avant d'appliquer la reconnaissance d'entités nommées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Question orale, @MicheleBonneton http://t.co/RrHxGn5URS)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MISC', 'LOC']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent.label_ for ent in tw.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Réduction par filtrage : suppression de certains mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. Filtrage des mots par fréquence d'utilisation en langue générale : \"mots vides\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critère vague. La notion de mot vide peut varier selon le contexte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. Filtrage des mots par contenu expressif : mots qui n'ont pas une polarité claire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moyennant un dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple : dictionnaire [FEEL](http://advanse.lirmm.fr/feel.php) (voir [article](https://hal-lirmm.ccsd.cnrs.fr/lirmm-01348016/document)) : liste de 14128 **lemmes** annotés en termes de polarité (positif/négatif) et de six émotions (joy, fear, sadness, anger, surprise, disgust)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire le dictionnaire et n'en garder que la colonne \"polarité\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En exploitant les fonctionnalités d'un outil de TAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calcul des valeurs des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Binaire : présence/absence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Numérique discret : décomptes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Numérique continu : pondérations diverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pistes pour l'approfondissement (travail personnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Combiner des descripteurs textuels (matrice mot-document) avec d'autres descripteurs.\n",
    "\n",
    "2. Pousser la réduction de variables plus loin : correction d'orthographe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Construire explicitement la matrice document-termes. Les \"termes\" (c.à.d. mots) sont des variables auxquelles on peut rajouter d'autres variables, de nature non-textuelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire un descripteur du fichier `json` correspondant à chaque tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche sans apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul d'un score de polarité pour chaque texte, selon la formule : (donner référence, cf. livre Bing Liu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela revient à un filtrage des mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche par apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous entraînerons des modèles appartenant à quelques familles d'algorithmes. D'autres familles restent à explorer. L'objectif est de comparer non seulement les performances des différentes méthodes entre elles, mais aussi la performance d'une même méthode sur des représentations différentes du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place du schéma d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schéma général : apprentissage (> évaluation > apprentissage > évaluation) > prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boîte à outils (algorithmes pré-implémentés) : `scikit-learn`. **Schéma de fonctionnement :**\n",
    "\n",
    "* création de l'objet estimateur : appel du constructeur de la classe pertinente, avec d'éventuels paramètres si valeurs autres que défaut ;\n",
    "\n",
    "* si besoin de réduire les données :\n",
    "    - création d'un objet `scaler` (réducteur des données) ;\n",
    "    - entraînement du `scaler` sur les données d'entraînement : méthode `fit` de l'objet réducteur ;\n",
    "    - réduction des données d'entraînement : méthode `transform` du réducteur ;\n",
    "    - réduction des données de validation : méthode `transform` du réducteur (attention : même réducteur que pour les données d'entraînement !) ;\n",
    "\n",
    "* apprentissage de l'estimateur sur les données d'entraînement (éventuellement réduites) : méthode `fit` de l'estimateur ;\n",
    "\n",
    "* évaluation sur les données d'entraînement, de validation et/ou (uniquement si c'est le modèle final !) de test : méthode `score` de l'estimateur.\n",
    "\n",
    "* prédiction  : méthode `predict` de l'estimateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métriques d'évaluation :**\n",
    "\n",
    "* taux de bonne classification (accuracy) ;\n",
    "\n",
    "* précision (precision) ;\n",
    "\n",
    "* recall (rappel) ;\n",
    "\n",
    "* score F1 ;\n",
    "\n",
    "* aire sous la courbe ROC (ROC AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Weak baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "np.max(class_distribution['perc_examples'])": "0.45000000000000001"
    }
   },
   "source": [
    "- Choix aléatoire (probabilités égales pour les trois classes) : accuracy = 1 / 3.\n",
    "\n",
    "- Prédiction constante de la classe majoritaire : accuracy = `{{np.max(class_distribution['perc_examples'])}}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Strong baseline : méthode du lexique polarisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Strong baseline : classifieur Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
