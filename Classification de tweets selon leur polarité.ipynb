{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectifs\n",
    "\n",
    "- **manipulation de textes** en vue de leur préparation pour une tâche d'apprentissage automatique : manipuler du texte \"authentique\" français produit par des internautes, pour en produire des représentations qui mettent en oeuvre une réduction des variables textuelles à différents degrés d'agressivité ;\n",
    "\n",
    "- **apprentissage automatique** : entraîner et évaluer des modèles de classification automatique des textes préparés ;\n",
    "\n",
    "- **maîtrise d'outils** : utilisation de librairies qui implémentent des fonctionnalités de manipulation de texte (`spacy`, `nltk`), de données tabulaires (`pandas`) ou d'apprentissage automatique (`scikit-learn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description de la tâche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tâche :__ classification (catégorisation) multi-classe (trois classes)\n",
    "\n",
    "__Output :__ polarité du texte: positif, négatif, neutre\n",
    "\n",
    "__Type de données :__ texte, tweets\n",
    "\n",
    "__Langue :__ français"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Installation et) importation des outils nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk : en général limité quant au traitement du français\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer # ou: from nltk.stem.snowball import FrenchStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# En ligne de commande\n",
    "# !pip install -U spacy\n",
    "## !python -m spacy download fr\n",
    "# !python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy : bonne couverture du français ; conçu spécifiquement pour s'interfacer avec des frameworks de deep learning\n",
    "import spacy\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION : Les données de test sont destinées à une évaluation FINALE du modèle entraîné. Elles ne doivent sous aucune forme servir à la conception du modèle. Il est donc interdit de les examiner. La sélection itérative du meilleur modèle se fera en évaluant les différentes variantes du modèle (en faisant varier des hyper-paramètres) sur un jeu de données de validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (A) Récupération et mise en forme des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données du défi [DEFT2015](https://deft.limsi.fr/2015/corpus.fr.php?lang=fr) : tweets rédigés en français, portant sur la thématique des changements climatiques. Tweets annotés selon leur polarité, pour la tâche 1 du défi : \"Classification des tweets selon leur polarité. Étant donné un tweet, cette tâche consiste à le classer, selon l’opinion/sentiment/émotion qu'il exprime, en positif, négatif, neutre ou mixte (si le tweet contient à la fois un sentiment positif et un sentiment négatif).\"\n",
    "\n",
    "__ATTENTION : Ces jeux de données ont été mis à notre disposition EXCLUSIVEMENT à des fins pédagogiques par les organisateurs du défi DEFT 2015. Leur redistribution est formellement interdite et tout travail écrit (rapport de stage, article, etc.) produit sur la base de ces données devra citer les sources indiquées sur le [site Web de DEFT 2015](https://deft.limsi.fr/2015/corpus.fr.php?lang=fr).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les étiquettes (la vérité terrain) et le texte des tweets sont stockés séparément. Nous les regrouperons à partir de l'identifiant du tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_label_file_path(parent_label_directory, train_or_test):\n",
    "    return os.path.join(parent_label_directory,\n",
    "                        '{}_References'.format(train_or_test.title()),\n",
    "                        'T1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_label_to_numeric(label):\n",
    "    return 1 if label == '+' else 0 if label == '=' else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(parent_label_directory, train_or_test):\n",
    "    label_file = make_label_file_path(parent_label_directory, train_or_test)\n",
    "    labels = pd.read_table(label_file, header=None, names=['id', 'polarity'])\n",
    "    labels['polarity'] = labels['polarity'].apply(map_label_to_numeric)\n",
    "    labels.set_index('id', inplace=True)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = get_labels('data', 'train')\n",
    "test_labels = get_labels('data', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    polarity\n",
       "id                          \n",
       "487349133460918272         1\n",
       "487354248959918080        -1\n",
       "487360225654374401         0\n",
       "487387097222098944        -1\n",
       "487387321537269761         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7929, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data_dir_path(parent_data_directory, train_or_test):\n",
    "    return os.path.join(parent_data_directory,\n",
    "                        'deft2015_{}_twitter_raw'.format(train_or_test.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweets(parent_data_directory, train_or_test):\n",
    "    if train_or_test == 'test':\n",
    "        train_or_test += 's' # incohérence dans le nommage des répertoires\n",
    "    data_dir = make_data_dir_path(parent_data_dir, train_or_test)\n",
    "    tweets = dict()\n",
    "\n",
    "    for file_name in sorted(os.listdir(data_dir)):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            with open(os.path.join(data_dir, file_name), 'r') as f:\n",
    "                text = f.read()\n",
    "            id_tweet = int(os.path.splitext(file_name)[0])\n",
    "            tweets[id_tweet] = text\n",
    "    \n",
    "    return (pd.DataFrame.from_dict(tweets, orient='index')\n",
    "                        .rename(columns={0: 'text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_data_dir = 'data/twitter'\n",
    "train_tweets = get_tweets(parent_data_dir, 'train')\n",
    "test_tweets = get_tweets(parent_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...\n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...\n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n\n",
       "487387097222098944                  Développement durable ma gueule\\n\n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*QUESTION : Combien de tweets y a-t-il dans le jeu de données d'entraînement et dans celui de test ?*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7511, 3285)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tweets), len(test_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Jonction des textes et des étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plus d'étiquettes que de textes, car des tweets ont pu disparaître entre le moment où ils ont été collectés pour l'annotation de référence et le moment où ils ont été récupérés ultérieurement (voir [ici](https://deft.limsi.fr/2015/evaluation.fr.php?lang=fr)). Nous ferons une jointure interne pour ne retenir que les éléments communs aux deux tableaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, tous les tweets disponibles ont une étiquette :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_tweets.index).intersection(set(train_labels.index))) == len(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_tweets_and_labels(tweets_df, labels_df):\n",
    "    return pd.merge(tweets_df, labels_df, how='inner',\n",
    "                    left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets = merge_tweets_and_labels(train_tweets, train_labels)\n",
    "test_tweets = merge_tweets_and_labels(test_tweets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...   \n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...   \n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n   \n",
       "487387097222098944                  Développement durable ma gueule\\n   \n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ...   \n",
       "\n",
       "                    polarity  \n",
       "487349133460918272         1  \n",
       "487354248959918080        -1  \n",
       "487360225654374401         0  \n",
       "487387097222098944        -1  \n",
       "487387321537269761         0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_distribution = (pd.DataFrame.from_dict(Counter(train_tweets.polarity.values),\n",
    "                                             orient='index')\n",
    "                                  .rename(columns={0: 'num_examples'}))\n",
    "class_distribution.index.name = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples\n",
       "class              \n",
       " 1             2364\n",
       "-1             1763\n",
       " 0             3384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_distribution['perc_examples'] = np.around(class_distribution.num_examples /\n",
    "                                                np.sum(class_distribution.num_examples), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_examples</th>\n",
       "      <th>perc_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2364</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1763</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3384</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_examples  perc_examples\n",
       "class                             \n",
       " 1             2364           0.31\n",
       "-1             1763           0.23\n",
       " 0             3384           0.45"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Exploration du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION :** Ne pas regarder les données de test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"#Question orale à @RoyalSegolene au sujet de l'efficacité énergétique de @MicheleBonneton http://t.co/RrHxGn5URS @Dailymotion\\n\",\n",
       "       \"@PhanEd @AznAlainT @_Baekholic alors j'ai une blague mais dure a comprendre: On est ecologiques a nous 3 on se rebelle groupe Anti-Train !\\n\",\n",
       "       '\"On peut vendre du vent, regarde les éoliennes\"\\n',\n",
       "       'Développement durable ma gueule\\n',\n",
       "       \"Quand l'cosystme numrique bordelais rencontre la mission French Tech nationale http://t.co/oCqL9tb4SZ\\n\",\n",
       "       'Madame Ségolène Royale, ministre de l\\'écologie et du développement durable : Non, à la destruction des \"nuisibles\" http://t.co/jUYWddlIMe\\n',\n",
       "       'Le nouveau Monsieur \" développement durable \": Jacques Tapin, l’ex-élu municipal niortais, vient d’être porté ... http://t.co/hrDGKOkyJd\\n',\n",
       "       'Le ciment s’offre une empreinte carbone réduite: Si le ciment est connu pour ses qualités écologiques, il est ... http://t.co/Gd028bTRe2\\n',\n",
       "       \"J'ai mis à jour mon profil Viadeo : http://t.co/pdQtQFh9Sz\\n\",\n",
       "       '@F_Choquette  pourquoi une pétition contre le changement climatique si vous etes meme pas capable de traiter un simple dossier citoyen\\n',\n",
       "       '\"Quand l\\'écosystème numérique bordelais rencontre la mission French Tech nationale …\"  http://t.co/QtgZ1zLIcT good read\\n',\n",
       "       \"Ad exchange et DMP: l'écosystème digital en route pour inventer les subprimes de la #pub en faisant croire bundle YouTube+socialTV+data=TF1?\\n\",\n",
       "       \"Content de participer au groupe de travail @LaFabriqueEcolo sur mondialisation et développement durable, beaucoup d'échanges et d'énergie\\n\",\n",
       "       \"Camping rime aujourd'hui avec technologie : la preuve en est avec cette tente aux capteurs solaires intégrés dans... http://t.co/ylRP0Ua5Wd\\n\",\n",
       "       '7 Principes de l’Engagement #RSE du #Dirigeant | @CalvoConstant http://t.co/QSorpZGxgE\\n'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets['text'].values[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) Représentation des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Du texte au numérique:**\n",
    "\n",
    "- les descripteurs (variables, features, traits) sont des unités textuelles (lemmes, racines, autres ; prises individuellement ou en séquences, mais sans égard à leur ordre ou relations : c'est l'approche en \"sac de mots\") ;\n",
    "\n",
    "- les valeurs de ces variables sont numériques : binaires, numériques discrètes, numériques continues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texte vs corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Traditionnellement : les descripteurs textuels sont calculés sur l'ensemble du corpus. Tous les textes sont représentés par le mêmes ensemble de descripteurs, ce qui fait que la représentation d'un texte est un grand vecteur épars de taille fixe (taille du vecteur = taille du vocabulaire du corpus).\n",
    "\n",
    "Approches appliquées dans l'état de l'art : chaque mot est représenté par un vecteur dense de valeurs réelles. Le texte est représenté par une aggrégation sous une certaine forme des représentations de ses mots constituants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sélection de descripteurs : prétraitements textuels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : réduire le nombre de descripteurs : réduire à un seul descripteur ceux qui sont équivalents (p. ex. deux mots qui ont été écrits avec et sans accents respectivement) ou qui peuvent être regroupés dans une classe d'équivalence (p. ex. remplacer toutes les instances de date par un mot fictif, p. ex. \"DATEEXPR\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques procédés : lemmatisation, racinisation, normalisation/correction orthographique, suppression des accents, mise en minuscules, suppression de la ponctuation, suppression de certains mots (mots dits \"vides\", autres mots), substitution de certains mots par un autre représentant leur appartenance à une classe, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la pratique certains ces procédés sont souvent appliqués ensemble ou bien ils peuvent être pris en charge par la boîte à outils d'apprentissage automatique (via la spécification de divers paramètres à certaines étape du processus), qui les applique alors en boîte noire. D'autre part, le choix d'appliquer ou non un certain procédé doit prendre en compte les besoins du contexte concret (p. ex. une mise en minuscules affecte-t-elle la reconnaissance d'entités nommées, si celle-ci est préconisée ?). Il n'y a pas de recette ! Mais on peut s'intéresser à ce qui a marché pour d'autres (en consultant la littérature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme entraînement à la manipulation du texte, nous verrons quelques exemples de transformation du texte. Nous produirons plusieurs versions de nos textes, qui pourront servir par la suite à l'étape d'apprentissage du classifieur et de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour illustrer l'effet des différentes transformations sur le texte, prenons comme exemple ce tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Bruxelles boude le #Fonds vert pour le #climat par @EuroActiv_FR | @Actuenviro http://t.co/eFKkE9W0GI\\n'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple\n",
    "tw = train_tweets['text'].iloc[100]\n",
    "tw_nlp = nlp(tw)\n",
    "tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Pas de sélection : mots tels quels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "Bruxelles\n",
      "boude\n",
      "le\n",
      "#\n",
      "Fonds\n",
      "vert\n",
      "pour\n",
      "le\n",
      "#\n",
      "climat\n",
      "par\n",
      "@EuroActiv_FR\n",
      "|\n",
      "@Actuenviro\n",
      "http://t.co/eFKkE9W0GI\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in tw_nlp:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Réduction par regroupement/uniformisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Lemmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "bruxelles\n",
      "bouder\n",
      "le\n",
      "#\n",
      "fonds\n",
      "vert\n",
      "pour\n",
      "le\n",
      "#\n",
      "climat\n",
      "par\n",
      "@euroactiv_fr\n",
      "|\n",
      "@actuenviro\n",
      "http://t.co/efkke9w0gi\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in tw_nlp:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Produire une version lemmatisée des tweets et la mettre dans une colonne `lemmas` dans la dataframe. Pour ce faire : créer une fonction qui lemmatise un texte ; appliquer cette fonction à la colonne `text` des deux dataframes (`train` et `test`). Attention, le traitement de toute la colonne peut prendre un peu de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatise_text(text):\n",
    "    text = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in text]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# bruxelles bouder le # fonds vert pour le # climat par @euroactiv_fr | @actuenviro http://t.co/efkke9w0gi \\n'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatise_text(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets['lemmas'] = train_tweets['text'].apply(lemmatise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "      <td>1</td>\n",
       "      <td># question oral à @royalsegolene au sujet de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>@phaned @aznalaint @_baekholic alors il avoir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>\" on pouvoir vendre du vent , regarder le éoli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "      <td>-1</td>\n",
       "      <td>développement durable mon gueuler \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "      <td>0</td>\n",
       "      <td>quand le cosystme numrique bordelais rencontre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...   \n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...   \n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n   \n",
       "487387097222098944                  Développement durable ma gueule\\n   \n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ...   \n",
       "\n",
       "                    polarity  \\\n",
       "487349133460918272         1   \n",
       "487354248959918080        -1   \n",
       "487360225654374401         0   \n",
       "487387097222098944        -1   \n",
       "487387321537269761         0   \n",
       "\n",
       "                                                               lemmas  \n",
       "487349133460918272  # question oral à @royalsegolene au sujet de l...  \n",
       "487354248959918080  @phaned @aznalaint @_baekholic alors il avoir ...  \n",
       "487360225654374401  \" on pouvoir vendre du vent , regarder le éoli...  \n",
       "487387097222098944               développement durable mon gueuler \\n  \n",
       "487387321537269761  quand le cosystme numrique bordelais rencontre...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets['lemmas'] = test_tweets['text'].apply(lemmatise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3283, 3)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Racines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Bruxelles',\n",
       " 'boude',\n",
       " 'le',\n",
       " '#Fonds',\n",
       " 'vert',\n",
       " 'pour',\n",
       " 'le',\n",
       " '#climat',\n",
       " 'par',\n",
       " '@EuroActiv_FR',\n",
       " '|',\n",
       " '@Actuenviro',\n",
       " 'http://t.co/eFKkE9W0GI']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('french')\n",
    "tokenizer = TweetTokenizer()\n",
    "tokenizer.tokenize(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tweets présentent des particularités par rapport à d'autres textes. Des outils conçus spécifiquement pour gérer ce type de texte existent. Par exemple, `nltk` propose un tokeniseur pour les tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Bruxelles',\n",
       " 'boude',\n",
       " 'le',\n",
       " '#Fonds',\n",
       " 'vert',\n",
       " 'pour',\n",
       " 'le',\n",
       " '#climat',\n",
       " 'par',\n",
       " '|',\n",
       " 'http://t.co/eFKkE9W0GI']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) \n",
    "# strip_handles supprime les @...\n",
    "# reduce_len réduit les séquences de caractères répétés plus de trois fois à des séquences de taille trois\n",
    "tokenizer.tokenize(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#bruxel\n",
      "boud\n",
      "le\n",
      "#fond\n",
      "vert\n",
      "pour\n",
      "le\n",
      "#climat\n",
      "par\n",
      "|\n",
      "http://t.co/efkke9w0g\n"
     ]
    }
   ],
   "source": [
    "for token in tokenizer.tokenize(tw):\n",
    "    print(stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Produire une version racinisée des tweets et la mettre dans une colonne `stems` dans la dataframe. Pour ce faire : créer une fonction qui racinise un texte ; appliquer cette fonction à la colonne `text` des deux dataframes (`train` et `test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    stemmer = SnowballStemmer('french')\n",
    "    stems = [stemmer.stem(token) for token in tokenizer.tokenize(text)]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#bruxel boud le #fond vert pour le #climat par | http://t.co/efkke9w0g'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets['stems'] = train_tweets['text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "      <td>1</td>\n",
       "      <td># question oral à @royalsegolene au sujet de l...</td>\n",
       "      <td>#question oral à au sujet de l'efficac énerget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>@phaned @aznalaint @_baekholic alors il avoir ...</td>\n",
       "      <td>alor j'ai une blagu mais dur a comprendr : on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>\" on pouvoir vendre du vent , regarder le éoli...</td>\n",
       "      <td>\" on peut vendr du vent , regard le éolien \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "      <td>-1</td>\n",
       "      <td>développement durable mon gueuler \\n</td>\n",
       "      <td>développ durabl ma gueul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "      <td>0</td>\n",
       "      <td>quand le cosystme numrique bordelais rencontre...</td>\n",
       "      <td>quand l'cosystm numriqu bordel rencontr la mis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...   \n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...   \n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n   \n",
       "487387097222098944                  Développement durable ma gueule\\n   \n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ...   \n",
       "\n",
       "                    polarity  \\\n",
       "487349133460918272         1   \n",
       "487354248959918080        -1   \n",
       "487360225654374401         0   \n",
       "487387097222098944        -1   \n",
       "487387321537269761         0   \n",
       "\n",
       "                                                               lemmas  \\\n",
       "487349133460918272  # question oral à @royalsegolene au sujet de l...   \n",
       "487354248959918080  @phaned @aznalaint @_baekholic alors il avoir ...   \n",
       "487360225654374401  \" on pouvoir vendre du vent , regarder le éoli...   \n",
       "487387097222098944               développement durable mon gueuler \\n   \n",
       "487387321537269761  quand le cosystme numrique bordelais rencontre...   \n",
       "\n",
       "                                                                stems  \n",
       "487349133460918272  #question oral à au sujet de l'efficac énerget...  \n",
       "487354248959918080  alor j'ai une blagu mais dur a comprendr : on ...  \n",
       "487360225654374401       \" on peut vendr du vent , regard le éolien \"  \n",
       "487387097222098944                           développ durabl ma gueul  \n",
       "487387321537269761  quand l'cosystm numriqu bordel rencontr la mis...  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets['stems'] = test_tweets['text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3283, 4)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3. Étiquettes morphosyntaxiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ\n",
      "PROPN\n",
      "VERB\n",
      "DET\n",
      "NOUN\n",
      "NOUN\n",
      "ADJ\n",
      "ADP\n",
      "DET\n",
      "NOUN\n",
      "NOUN\n",
      "ADP\n",
      "NOUN\n",
      "ADJ\n",
      "AUX\n",
      "AUX\n",
      "SPACE\n"
     ]
    }
   ],
   "source": [
    "for token in tw_nlp:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Produire une version des tweets où chaque token est remplacé par son étiquette morphosyntaxique et la mettre dans une colonne `pos` dans la dataframe. Pour ce faire : créer une fonction qui remplace les mots par leurs étiquettes dans un texte ; appliquer cette fonction à la colonne `text` des deux dataframes (`train` et `test`). Attention, le traitement de toute la colonne peut prendre un peu de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_words_with_pos_tag(text):\n",
    "    text = nlp(text)\n",
    "    return ' '.join([token.pos_ for token in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ PROPN VERB DET NOUN NOUN ADJ ADP DET NOUN NOUN ADP NOUN ADJ AUX AUX SPACE'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_words_with_pos_tag(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tweets['pos'] = train_tweets['text'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>stems</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487349133460918272</th>\n",
       "      <td>#Question orale à @RoyalSegolene au sujet de l...</td>\n",
       "      <td>1</td>\n",
       "      <td># question oral à @royalsegolene au sujet de l...</td>\n",
       "      <td>#question oral à au sujet de l'efficac énerget...</td>\n",
       "      <td>PRON NOUN ADJ ADP PROPN PRON NOUN ADP DET NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487354248959918080</th>\n",
       "      <td>@PhanEd @AznAlainT @_Baekholic alors j'ai une ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>@phaned @aznalaint @_baekholic alors il avoir ...</td>\n",
       "      <td>alor j'ai une blagu mais dur a comprendr : on ...</td>\n",
       "      <td>ADP DET NOUN ADV PRON VERB DET NOUN CCONJ ADJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487360225654374401</th>\n",
       "      <td>\"On peut vendre du vent, regarde les éoliennes\"\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>\" on pouvoir vendre du vent , regarder le éoli...</td>\n",
       "      <td>\" on peut vendr du vent , regard le éolien \"</td>\n",
       "      <td>PUNCT PRON AUX VERB DET NOUN PUNCT CCONJ DET N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387097222098944</th>\n",
       "      <td>Développement durable ma gueule\\n</td>\n",
       "      <td>-1</td>\n",
       "      <td>développement durable mon gueuler \\n</td>\n",
       "      <td>développ durabl ma gueul</td>\n",
       "      <td>NOUN ADJ DET NOUN SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487387321537269761</th>\n",
       "      <td>Quand l'cosystme numrique bordelais rencontre ...</td>\n",
       "      <td>0</td>\n",
       "      <td>quand le cosystme numrique bordelais rencontre...</td>\n",
       "      <td>quand l'cosystm numriqu bordel rencontr la mis...</td>\n",
       "      <td>SCONJ DET NOUN ADJ ADJ VERB DET NOUN PROPN PRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "487349133460918272  #Question orale à @RoyalSegolene au sujet de l...   \n",
       "487354248959918080  @PhanEd @AznAlainT @_Baekholic alors j'ai une ...   \n",
       "487360225654374401  \"On peut vendre du vent, regarde les éoliennes\"\\n   \n",
       "487387097222098944                  Développement durable ma gueule\\n   \n",
       "487387321537269761  Quand l'cosystme numrique bordelais rencontre ...   \n",
       "\n",
       "                    polarity  \\\n",
       "487349133460918272         1   \n",
       "487354248959918080        -1   \n",
       "487360225654374401         0   \n",
       "487387097222098944        -1   \n",
       "487387321537269761         0   \n",
       "\n",
       "                                                               lemmas  \\\n",
       "487349133460918272  # question oral à @royalsegolene au sujet de l...   \n",
       "487354248959918080  @phaned @aznalaint @_baekholic alors il avoir ...   \n",
       "487360225654374401  \" on pouvoir vendre du vent , regarder le éoli...   \n",
       "487387097222098944               développement durable mon gueuler \\n   \n",
       "487387321537269761  quand le cosystme numrique bordelais rencontre...   \n",
       "\n",
       "                                                                stems  \\\n",
       "487349133460918272  #question oral à au sujet de l'efficac énerget...   \n",
       "487354248959918080  alor j'ai une blagu mais dur a comprendr : on ...   \n",
       "487360225654374401       \" on peut vendr du vent , regard le éolien \"   \n",
       "487387097222098944                           développ durabl ma gueul   \n",
       "487387321537269761  quand l'cosystm numriqu bordel rencontr la mis...   \n",
       "\n",
       "                                                                  pos  \n",
       "487349133460918272  PRON NOUN ADJ ADP PROPN PRON NOUN ADP DET NOUN...  \n",
       "487354248959918080  ADP DET NOUN ADV PRON VERB DET NOUN CCONJ ADJ ...  \n",
       "487360225654374401  PUNCT PRON AUX VERB DET NOUN PUNCT CCONJ DET N...  \n",
       "487387097222098944                            NOUN ADJ DET NOUN SPACE  \n",
       "487387321537269761  SCONJ DET NOUN ADJ ADJ VERB DET NOUN PROPN PRO...  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweets['pos'] = test_tweets['text'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3283, 5)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4. Classe d'appartenance des entités nommées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limites : reconnaissance imparfaite. Faire des essais pour appréhender les limites de l'outil. Cela nous permettra, par exemple, de corriger certaines erreurs systématiques de l'outil en intervenant en amont sur le texte pour transformer les éléments qui posent difficulté. Par exemple, dans notre cas, l'outil semble ne pas bien gérer les URL. On peut donc penser à les normaliser avant d'appliquer la reconnaissance d'entités nommées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bruxelles, Fonds vert, | @Actuenviro, )"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_nlp.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOC', 'ORG', 'MISC', 'MISC']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent.label_ for ent in tw_nlp.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des erreurs : la chaîne vide a été identifiée comme entité de la classe MISC ; la troisième entité inclut un caractère séparateur suivi d'un espace. Ces erreurs pourraient probablement être évitées par un nettoyage du texte en amont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Produire une version des tweets où chaque entité nommée identifiée est remplacée par sa catégorie et la mettre dans une colonne `entities` dans la dataframe. Pour ce faire : créer une fonction qui remplace les entités par leurs étiquettes dans un texte ; appliquer cette fonction à la colonne `text` des deux dataframes (`train` et `test`). Attention, le traitement de toute la colonne peut prendre un peu de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'other' has incorrect type (expected spacy.tokens.token.Token, got spacy.tokens.span.Span)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-258-0b6eccf8b42e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtw_nlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtw_nlp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-258-0b6eccf8b42e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtw_nlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtw_nlp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'other' has incorrect type (expected spacy.tokens.token.Token, got spacy.tokens.span.Span)"
     ]
    }
   ],
   "source": [
    "[token.label_ if token in tw_nlp.ents else token for token in tw_nlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'other' has incorrect type (expected spacy.tokens.span.Span, got str)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-262-65f2db9f9724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtw_nlp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtw_nlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'other' has incorrect type (expected spacy.tokens.span.Span, got str)"
     ]
    }
   ],
   "source": [
    "for token in tw_nlp:\n",
    "    if token.text in tw_nlp.ents:\n",
    "        print(token.label_)\n",
    "    else:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_entities(text):\n",
    "    text = nlp(text)\n",
    "    entities = text.ents\n",
    "    [token.label_ else token if token in entities for token in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5. Autres classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme exemple, nous remplacerons les adresses Web par un mot fictif URLEXPR. N'hésitez pas à penser à d'autres classes d'équivalence qui vous semblent pertinentes !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Créer une fonction `substitute_url` qui prend en entrée une chaîne de caractères et le mot de remplacement (p. ex. \"URLEXPR\") et remplace les URL présentes dans la chaîne de caractères par le mot de remplacement donné en argument. Indication : utiliser des expressions régulières (module `re`) ; examiner des exemples de tweets (du corpus \n",
    "d'entraînement) pour bien saisir la structure des URL. Appliquer ensuite cette fonction à la colonne `text` des dataframes d'entraînement et de test. Dans les deux cas, stocker le résultat de la transformation dans une nouvelle colonne `url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Réduction par filtrage : suppression de certains mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. Filtrage des mots par fréquence d'utilisation en langue générale : \"mots vides\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critère vague. La notion de mot vide peut varier selon le contexte. En général géré lors de la création de la matrice documents-termes (voir plus bas, pour le calcul des valeurs des descripteurs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. Filtrage des mots par contenu expressif : mots qui n'ont pas une polarité claire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous reviendrons sur ce procédé quand nous aborderons les baselines pour notre tâche de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moyennant un dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple : dictionnaire [FEEL](http://advanse.lirmm.fr/feel.php) (voir [article](https://hal-lirmm.ccsd.cnrs.fr/lirmm-01348016/document)) : liste de 14128 **lemmes** annotés en termes de polarité (positif/négatif) et de six émotions (joy, fear, sadness, anger, surprise, disgust)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En exploitant les fonctionnalités d'un outil de TAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains outils, dont `spacy`, peuvent attacher un score de sentiment aux tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calcul des valeurs des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de procéder aux calculs, nous séparerons un jeu de données de validation à partir des données d'entraînement initiales. Nous mettons les données de test fournies de côté, exclusivement pour une évaluation finale des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gizmo/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_tweets['text'],\n",
    "                                                      train_tweets['polarity'],\n",
    "                                                      train_size=0.75,\n",
    "                                                      random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5633,), (1878,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = test_tweets['text'], test_tweets['polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Binaire : présence/absence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Numérique discret : décomptes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étudier la documentation du constructeur. De nombreuses options de réduction du vocabulaire sont proposées. En voici quelques-unes :\n",
    "\n",
    "- suppression des accents : `strip_accents` ;\n",
    "\n",
    "- mise en minuscule : `lowercase` (par défault `True`) ;\n",
    "\n",
    "- seuillage sur la fréquence documentaire (c.à.d. le nombre de documents dans lesquels le terme apparaît) ; exemple : `max_df=0.7` signifie qu'on ignore les termes qui sont présentes dans plus de 70% des textes du corpus (ce qui équivaut à l'élimination des mots vides propres au corpus) ; `min_df=5` ignore les termes qui apparaissent dans moins de 5 textes du corpus ;\n",
    "\n",
    "- seuillage du nombre de variables à retenir : `max_features=1000` ne retient que les 1000 termes qui ont les \"term frequency\" (nombre d'occurrences dans un texte particulier) les plus élevées ;\n",
    "\n",
    "- suppression de mots vides : `stop_words` (liste par défaut ou fournie) ;\n",
    "\n",
    "- ordre des n-grammes : `ngram_range=(min_n, max_n)` extrait les n-grammes dont la taille est entre `min_n` et `max_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcul des fréquences d'occurrence des termes dans le corpus, avec les options par défaut\n",
    "vect_count = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons le vocabulaire de notre corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '01',\n",
       " '013',\n",
       " '01business_fr',\n",
       " '01iwiyyjyj',\n",
       " '01kcbtpxur',\n",
       " '01net',\n",
       " '02',\n",
       " '03',\n",
       " '034jkracav',\n",
       " '03gvexadww',\n",
       " '03vuozibff',\n",
       " '04',\n",
       " '05',\n",
       " '0539oglj1k',\n",
       " '06',\n",
       " '07',\n",
       " '077707',\n",
       " '07la',\n",
       " '08',\n",
       " '08ovazgsvp',\n",
       " '08xaecp2qb',\n",
       " '09',\n",
       " '09pgnr35va',\n",
       " '09ushmifhr',\n",
       " '0agsmeki3s',\n",
       " '0ar2oto063',\n",
       " '0bdfmc9xye',\n",
       " '0bevqostpr',\n",
       " '0c0dgfcl3n',\n",
       " '0cbub6cr8l',\n",
       " '0cqryb3www',\n",
       " '0dbeqd7q64',\n",
       " '0dv74sttev',\n",
       " '0ed5jl9dsr',\n",
       " '0eip8htosr',\n",
       " '0em2kxoym1',\n",
       " '0epbnsrqfs',\n",
       " '0fftvqzrkz',\n",
       " '0gcaqeuxga',\n",
       " '0gzv2i2f4p',\n",
       " '0hu6xafz3u',\n",
       " '0husujgd5b',\n",
       " '0hyt8ayhai',\n",
       " '0iqdmldjxz',\n",
       " '0jyqssje6d',\n",
       " '0k7vgj8vsh',\n",
       " '0l0iwtbj81',\n",
       " '0lfq23fxux',\n",
       " '0lwhyffmak',\n",
       " '0mamllnhqy',\n",
       " '0msqmx44xw',\n",
       " '0napsdwx4w',\n",
       " '0nmate58kc',\n",
       " '0nwxmzvjex',\n",
       " '0ofvoxacdy',\n",
       " '0okkgzqrho',\n",
       " '0om4showzg',\n",
       " '0oqsf3kbcn',\n",
       " '0qtf3xttzc',\n",
       " '0ssbgvyopk',\n",
       " '0tjsewjv1a',\n",
       " '0u68bgwyry',\n",
       " '0uh1umaeiq',\n",
       " '0uosjy9thu',\n",
       " '0us6f1caqt',\n",
       " '0uyvnhzk90',\n",
       " '0vjeeewvmo',\n",
       " '0w1aptxpzw',\n",
       " '0wtuv9jixw',\n",
       " '0xafumcdor',\n",
       " '0xeawyhewf',\n",
       " '0xqldwu9dh',\n",
       " '0xu4zilnzs',\n",
       " '0xu4zj3xda',\n",
       " '0yo3jpslsw',\n",
       " '0z3scgtqcg',\n",
       " '0z6b7qq34q',\n",
       " '0z7pmndd5f',\n",
       " '0zjwn3ykxg',\n",
       " '0zudjkvwdi',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000vaches',\n",
       " '1000w',\n",
       " '100vegetal',\n",
       " '105',\n",
       " '10c8hrmb6x',\n",
       " '10e',\n",
       " '10h',\n",
       " '10h30',\n",
       " '10l',\n",
       " '10oq2anuer',\n",
       " '11',\n",
       " '110',\n",
       " '11000',\n",
       " '115',\n",
       " '118']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['équilibre',\n",
       " 'équipe',\n",
       " 'équipements',\n",
       " 'équipent',\n",
       " 'équipée',\n",
       " 'équipés',\n",
       " 'équitable',\n",
       " 'équitables',\n",
       " 'équiterre',\n",
       " 'équivalent',\n",
       " 'équivoque',\n",
       " 'ér',\n",
       " 'érable',\n",
       " 'érection',\n",
       " 'érige',\n",
       " 'éro',\n",
       " 'érosion',\n",
       " 'éruptions',\n",
       " 'és',\n",
       " 'ésente',\n",
       " 'établi',\n",
       " 'établir',\n",
       " 'étage',\n",
       " 'étaient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étals',\n",
       " 'étant',\n",
       " 'étape',\n",
       " 'étapes',\n",
       " 'état',\n",
       " 'états',\n",
       " 'éteindre',\n",
       " 'éteintes',\n",
       " 'étendent',\n",
       " 'étendre',\n",
       " 'éthanol',\n",
       " 'éthiopie',\n",
       " 'éthique',\n",
       " 'éthiques',\n",
       " 'étienne',\n",
       " 'étique',\n",
       " 'étoffé',\n",
       " 'étoile',\n",
       " 'étonnant',\n",
       " 'étonnante',\n",
       " 'étonne',\n",
       " 'étonnes',\n",
       " 'étonnée',\n",
       " 'étourdissant',\n",
       " 'étrange',\n",
       " 'étrangère',\n",
       " 'étrangères',\n",
       " 'étre',\n",
       " 'étroit',\n",
       " 'étroites',\n",
       " 'étude',\n",
       " 'études',\n",
       " 'étudiant',\n",
       " 'étudiante',\n",
       " 'étudiants',\n",
       " 'étudie',\n",
       " 'été',\n",
       " 'éunion',\n",
       " 'évacuation',\n",
       " 'évaluation',\n",
       " 'évaluer',\n",
       " 'évangé',\n",
       " 'évangéliste',\n",
       " 'éveil',\n",
       " 'éveloppement',\n",
       " 'évidemment',\n",
       " 'évidence',\n",
       " 'évident',\n",
       " 'évier',\n",
       " 'éviter',\n",
       " 'évolue',\n",
       " 'évoluent',\n",
       " 'évoluer',\n",
       " 'évolution',\n",
       " 'évolutions',\n",
       " 'évoquant',\n",
       " 'évoque',\n",
       " 'évoquer',\n",
       " 'évoqués',\n",
       " 'événementiel',\n",
       " 'éé',\n",
       " 'ête',\n",
       " 'êtes',\n",
       " 'être',\n",
       " 'êtres',\n",
       " 'îdf',\n",
       " 'île',\n",
       " 'îles',\n",
       " 'œnotourisme',\n",
       " 'œuvre',\n",
       " 'œuvres',\n",
       " 'الجزائر',\n",
       " 'นห',\n",
       " 'วาเลนไทน']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names()[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17673"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names()) # taille du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5633x17673 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 84342 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création de la matrice document-termes\n",
    "X_train_vectorized_count = vect_count.transform(X_train)\n",
    "X_train_vectorized_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Le corpus de validation et celui de test doivent être également transformées en matrice document-termes. Les termes sont ceux décomptés sur le corpus d'entraînement. Les termes présent dans le corpus de validation ou de test mais absents du corpus d'entraînement seront ignorés.\n",
    "X_valid_vectorized_count = vect_count.transform(X_valid)\n",
    "X_test_vectorized_count = vect_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci nous allons inclure des bigrammes dans le vocabulaire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3920"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count_bigrams = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vectorized_count_bigrams = vect_count_bigrams.transform(X_train)\n",
    "X_valid_vectorized_count_bigrams = vect_count_bigrams.transform(X_valid)\n",
    "X_test_vectorized_count_bigrams = vect_count_bigrams.transform(X_test)\n",
    "len(vect_count_bigrams.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Numérique continu : TF-IDF (ou autres pondérations diverses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitons le vocabulaire à des termes qui apparaissent dans au moins 5 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_tfidf = TfidfVectorizer(min_df=5).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La réduction de la taille du vocabulaire est spectaculaire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17673, 2039)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names()), len(vect_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf = vect_tfidf.transform(X_train)\n",
    "X_valid_vectorized_tfidf = vect_tfidf.transform(X_valid)\n",
    "X_test_vectorized_tfidf = vect_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous entraînerons des modèles de classification appartenant à quelques familles d'algorithmes d'apprentissage automatique. D'autres familles restent à explorer. L'objectif est de comparer non seulement les performances des différentes méthodes entre elles, mais aussi la performance d'une même méthode sur des représentations différentes du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schéma général :** apprentissage (> évaluation sur données de validation > apprentissage > évaluation sur données de validation >...) (> évaluation sur données de test) > prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boîte à outils (algorithmes pré-implémentés) : `scikit-learn`. Interface unifiée pour l'ensemble des algorithmes. **Mise en oeuvre :**\n",
    "\n",
    "* si besoin de réduire et/ou centrer les données (réduction statistique) :\n",
    "    - création d'un objet `scaler` de la classe adaptée (réducteur des données) ;\n",
    "    - entraînement du `scaler` sur les données d'entraînement : méthode `fit` de l'objet réducteur ;\n",
    "    - réduction des données d'entraînement : méthode `transform` du réducteur ; cette étape peut être enchaînée avec la précédente grâce à la méthode `fit_transform` du réducteur ;\n",
    "    - réduction des données de validation et de test : méthode `transform` du réducteur (attention : même réducteur que pour les données d'entraînement ! On ne réapprend pas les critères de réduction sur les données de validation/test !) ;\n",
    "\n",
    "\n",
    "* création de l'objet estimateur : appel du constructeur de la classe pertinente, avec d'éventuels paramètres si valeurs autres que défaut ;\n",
    "\n",
    "* apprentissage de l'estimateur sur les données d'entraînement (éventuellement réduites) : méthode `fit` de l'estimateur ; cette étape peut être enchaînée avec la précédente ;\n",
    "\n",
    "* évaluation de l'estimateur sur les données d'entraînement, de validation et/ou (uniquement si c'est le modèle final !) de test : méthode `score` de l'estimateur.\n",
    "\n",
    "* prédiction sur des données nouvelles : méthode `predict` de l'estimateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métriques d'évaluation :**\n",
    "\n",
    "* taux de bonne classification (*accuracy*) ;\n",
    "\n",
    "* précision (*precision*) ;\n",
    "\n",
    "* recall (*rappel*) ;\n",
    "\n",
    "* score F1 ;\n",
    "\n",
    "* aire sous la courbe ROC (ROC AUC) : pour la classification binaire ;\n",
    "\n",
    "* métriques \"maison\", sur mesure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Créer une fonction appelée `score_on_dataset`, qui prend en entrée un modèle entraîné, un jeu de données et les étiquettes correspondant à celui-ci, et retourne un dictionnaire contenant les scores du modèle sur le jeu de données. Le dictionnaire aura cette forme :\n",
    "\n",
    "`{'confusion_matrix': [[..., ...], ...], 'accuracy': 0.85, 'precision': 0.7, 'recall': ..., 'F1_macro': ..., 'F1_micro': ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Créer une fonction qui, en appelant la fonction `score_on_dataset`, évalue le modèle sur les données d'entraînement et de validation, et retourne un dictionnaire de dictionnaires contenant les scores du modèle sur les deux jeux de données. Le dictionnaire aura cette forme :\n",
    "\n",
    "`{'train': {'confusion_matrix': [[..., ...], ...],\n",
    "            'accuracy': 0.85,\n",
    "            'precision': 0.7,\n",
    "            'recall': ...,\n",
    "            'F1_macro': ...,\n",
    "            'F1_micro': ...},\n",
    " 'validation': {'confusion_matrix': [[..., ...], ...],\n",
    "                'accuracy': ...,\n",
    "                'precision': 0.7,\n",
    "                'recall': ...,\n",
    "                'F1_macro': ...,\n",
    "                'F1_micro': ...},\n",
    " }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modèles de référence faibles (*weak baselines*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Choix aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le taux de bonne classification (*accuracy*) est la probabilité de choisir une classe. Toutes les classes ont les mêmes chances d'être choisies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Quelle est le taux de bonne classification pour cette approche dans notre scénario ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Prédiction constante de la classe majoritaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seules les instances de la classe majoritaire seront classées correctement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Quelle est le taux de bonne classification pour cette approche dans notre scénario ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez votre réponse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "maj = DummyClassifier(strategy='most_frequent').fit(X_train_vectorized, y_train)\n",
    "predictions_valid = maj.predict(vect.transform(X_valid))\n",
    "predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj_class = (class_distribution.index[class_distribution.perc_examples ==\n",
    "                                      np.amax(class_distribution.perc_examples)][0])\n",
    "maj_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(predictions_valid == maj_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45527156549520764"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj.score(X_valid_vectorized, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modèle de référence fort (*strong baseline*) : approche sans apprentissage automatique : méthode du lexique de polarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul d'un score de polarité pour chaque texte, selon la formule (simplifiée) : nombre_de_termes_positifs - nombre_de_termes_négatifs ([Hu et Liu (2004)](https://pdfs.semanticscholar.org/13e5/f0c40c85ca8e01b3756963d5352358de7c29.pdf), [Kim et Hovy (2004)](http://anthology.aclweb.org/P/P06/P06-2.pdf#page=493)). Cela revient à un filtrage des mots, suivi d'un calcul de score. Des variantes affinées de cette approche ont été proposées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Classifieur Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En général pris également comme baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb = MultinomialNB().fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.626730564430245"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.47      0.57       466\n",
      "          0       0.60      0.82      0.69       855\n",
      "          1       0.63      0.46      0.53       557\n",
      "\n",
      "avg / total       0.64      0.63      0.61      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Entraîner un modèle avec les arguments suivants : `multi_class='multinomial'`, `solver='lbfgs'` sur le corpus vectorisé par nombre d'occurrences et l'évaluer sur le corpus de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = model_lr.predict(X_valid_vectorized_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66027689030883918"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.54      0.62       466\n",
      "          0       0.65      0.78      0.71       855\n",
      "          1       0.62      0.58      0.60       557\n",
      "\n",
      "avg / total       0.67      0.66      0.66      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons les variables (termes) ayant l'association la plus forte avec chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_n_strongly_associated_features(vectoriser, model, n):\n",
    "    feature_names = np.array(vectoriser.get_feature_names())\n",
    "\n",
    "    for i in range(3):\n",
    "        class_name = model.classes_[i]\n",
    "        print(\"CLASSE {}\".format(class_name))\n",
    "        idx_coefs_sorted = model.coef_[i].argsort()\n",
    "        print(\"Les dix variables ayant l'association négative la plus forte \" + \n",
    "              \"avec la classe {} :\\n{}\\n\".format(class_name,\n",
    "                                                 feature_names[idx_coefs_sorted[:n]]))\n",
    "        print(\"Les dix variables ayant l'association positive la plus forte \" +\n",
    "              \"avec la classe {} :\\n{}\\n\"\n",
    "              .format(class_name,\n",
    "                      feature_names[idx_coefs_sorted[:-(n + 1):-1]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSE -1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe -1 :\n",
      "['traitement' 'article' 'photovoltaïques' 'renouvelables' 'grâce' 'peuvent'\n",
      " 'raison' 'décision' 'réaction' 'comprendre']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe -1 :\n",
      "['menace' 'danger' 'scandale' 'mal' 'acidification' 'menacée' 'gueule'\n",
      " 'rejette' 'noire' 'crise']\n",
      "\n",
      "\n",
      "CLASSE 0\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 0 :\n",
      "['contre' 'grande' 'merci' 'veut' 'grand' 'bonne' 'menace' 'bravo' 'espèce'\n",
      " 'aime']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 0 :\n",
      "['fois' 'french' 'cap' 'art' 'algérie' '11' 'ni' 'consultation' 'dis'\n",
      " 'montre']\n",
      "\n",
      "\n",
      "CLASSE 1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 1 :\n",
      "['mal' 'piège' 'eoliennes' 'promotion' 'oiseaux' 'communistes' 'fois'\n",
      " 'danger' 'presse' 'abandon']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 1 :\n",
      "['bonne' 'intéressant' 'crowdfunding' 'réduire' 'maintien' 'soutien' 'veut'\n",
      " 'aime' 'soutenir' 'merci']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_n_strongly_associated_features(vect_count, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCICE.** Entraîner un modèle avec les arguments suivants : `multi_class='multinomial'`, `solver='lbfgs'` sur le corpus vectorisé par TF-IDF et l'évaluer sur le corpus de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63099041533546329"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.71      0.50      0.58       466\n",
      "          0       0.63      0.77      0.69       855\n",
      "          1       0.59      0.54      0.56       557\n",
      "\n",
      "avg / total       0.64      0.63      0.63      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance est légèrement inférieure, mais nous l'avons obtenue en utilisant considérablement moins de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF le moins élevé : ['recuperats' '2fkd2lpde9' 'x1js7tox3c' 'culminant' 'bilans' 'aliments'\n",
      " '06' 'taller' 'dinar' 'aprofitament']\n",
      "TF-IDF le plus élevé : ['écologique' 'éoliennes' 'écologie' 'eolienne' 'air' 'ah' 'maroc'\n",
      " 'écologiques' 'scoopit' 'bonjour']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect_tfidf.get_feature_names())\n",
    "idx_tfidf_sorted = X_train_vectorized_tfidf.max(0).toarray()[0].argsort()\n",
    "print(\"TF-IDF le moins élevé : {}\".format(feature_names[idx_tfidf_sorted[:10]]))\n",
    "print(\"TF-IDF le plus élevé : {}\".format(feature_names[idx_tfidf_sorted[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le vectorisateur à **unigrammes et bigrammes** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_count_bigrams,\n",
    "                                                  y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.626730564430245"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.52      0.60       466\n",
      "          0       0.64      0.73      0.68       855\n",
      "          1       0.57      0.56      0.56       557\n",
      "\n",
      "avg / total       0.63      0.63      0.62      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSE -1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe -1 :\n",
      "['raison' 'photovoltaïques' 'article' 'énergies renouvelables' 'voir'\n",
      " 'la chasse' 'pourraient' 'je ne' 'fil' 'vivre']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe -1 :\n",
      "['menace' 'gueule' 'quitte' 'danger' 'noire' 'mal' 'pénurie' 'pire' 'non'\n",
      " 'crise']\n",
      "\n",
      "\n",
      "CLASSE 0\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 0 :\n",
      "['menace' 'belles' 'hausse' 'belle' 'veut' 'aime' 'bravo' 'crise'\n",
      " 'contre le' 'bonne']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 0 :\n",
      "['consultation' 'ses éoliennes' 'énergétique de' 'arrive' 'de innovation'\n",
      " 'cours' 'qui se' 'art' '11' 'inter']\n",
      "\n",
      "\n",
      "CLASSE 1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 1 :\n",
      "['énergétique de' 'est le' 'frein' 'abandon' 'disparition' 'eoliennes'\n",
      " 'mal' 'octobre' 'de innovation' 'lepoint']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 1 :\n",
      "['bonne' 'intéressant' 'aime' 'soutien' 'réduire' 'soutenir' 'alimenter'\n",
      " 'lancement' 'au http' 'félicitations']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_n_strongly_associated_features(vect_count_bigrams, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.1).fit(X_train_vectorized_count_bigrams, y_train)\n",
    "predictions_valid = model_svm.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62087326943556975"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.72      0.47      0.57       466\n",
      "          0       0.60      0.82      0.69       855\n",
      "          1       0.61      0.45      0.52       557\n",
      "\n",
      "avg / total       0.63      0.62      0.61      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pistes pour l'approfondissement (travail personnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Pousser la réduction de variables plus loin : correction d'orthographe, autres transformations considérées pertinentes. Il n'y a pas de recette qui vaille partout, il faut essayer différentes approches et voir ce qui marche le mieux sur nos textes et notre tâche. Le texte des tweets pose des problèmes particulier, il faut donc y adapter les traitements.\n",
    "\n",
    "**2.** Combiner des descripteurs textuels avec des variables non-textuelles. Il faudra construire explicitement la matrice document-termes (et appliquer probablement un filtrage plus agressif, pour des raisons de coût de mémoire) pour pouvoir l'augmenter d'autres variables. Le fichier `json` correspondant à chaque tweet contient des méta-données. En choisir une ou deux, les extraire et les ajouter à la représentation des données. Puis entraîner un modèle de classification sur ce nouveau jeu de descripteurs.\n",
    "\n",
    "**3.** Essayer d'autres algorithmes de classification, par exemple : arbres de décision (`from sklearn.tree import DecisionTreeClassifier`), méthodes d'ensemble (forêts aléatoires : `from sklearn.ensemble import RandomForestClassifier` ; gradient-boosted decision trees : `from sklearn.ensemble import GradientBoostingClassifier`), réseaux de neurones simple (`from sklearn.neural_network import MLPClassifier`) ou bien des architectures plus complexes (autres librairies : `tensorflow`, `keras`, etc.).\n",
    "\n",
    "**4.** Ajuster les hyper-paramètres d'un modèle par validation croisée (`from sklearn.model_selection import GridSearchCV`). Utiliser dans ce cas la totalité du jeu d'entraînement fourni initialement (ne plus en séparer une portion pour la validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
